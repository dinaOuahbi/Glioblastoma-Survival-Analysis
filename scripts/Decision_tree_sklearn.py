# -*- coding: utf-8 -*-
"""Audrey_thesis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NxyNbEioRKyHLATNXCTk_K35CSPVFYRL
"""

'''
ANALYSE DE DONNEES
- CANCER / GLIOME
- AUTEUR DE SCRIPT / O DINA
- ETUDE / AUDREY (INTERNE EN NEUROCHIRURGIE)


LES DONNEES BRUTE ET TRAITEES SONT STOCKEES DANS K:\Bioinfo\Projets\Recherche\GLI\CLI\01\Donnees
LES RESULTAT SONT STOCKES DANS K:\Bioinfo\Projets\Recherche\GLI\CLI\01\Analyses_stats\results
'''




'''
ce code implemente un modele d'arbre de decision entrainné sur le variables d'interet (voir analyse multivaré sur R) pour predire au mieux deux parametres :
    - d'un coté le predicteur lineaire qui a été dichotomisé sur la mediane (on obtient donc les deux classe HIGH et LOW) ===> pour cela un modéle de classification a été mise en inplace
    - d'un autre coté la PFS (mois)  ===> pour cela un modéle de regression a été mise en inplace
'''
# In[187]:


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
get_ipython().run_line_magic('matplotlib', 'inline')
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report, confusion_matrix


# In[188]:


np.random.seed(1)


# In[189]:

# import and select
myTable = pd.read_csv('myTable_without_na.csv', index_col=0)
myTable.set_index('ID', inplace=True)
df = myTable[['COMORBIDITY', 'TYPECHIR1_bis', 'TYPECHIR2', 'pred_dicho']]


# In[190]:


df.head()


# In[196]:

# attention, l'arbrre de decision ne reconnai pas les var de type objet, il faut alors les transformé avant tout
df['COMORBIDITY']=df['COMORBIDITY'].astype('O')
df.dtypes


# In[197]:


X = df.drop('pred_dicho', axis=1)
y = df['pred_dicho']


# pour les variable de type objet, il faut tjrs fait un HOT ENCODING avant de passé a l'entrainnement sinon le modéle est perché
X = pd.get_dummies(X[['COMORBIDITY','TYPECHIR1_bis','TYPECHIR2']],drop_first=False)


# une separation en train et en test est evidente, inutile de tester le modéle sur ce qu'il connait deja ...
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)


# au debut, on construit le modele en gardant les hyperparametres par defaut pour voir deja quesqu'il en ai
classifier = DecisionTreeClassifier()
classifier.fit(X_train, y_train)

y_pred = classifier.predict(X_test)

print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))



# un graphe d'arbre de decision
fig = plt.figure(figsize=(25,20))
_ = tree.plot_tree(classifier,
                   feature_names=X.columns,
                   class_names=y.unique(),
                   filled=True)


# # OPTIMIZATION : maintenant, il est important d'essayaer de regler le modéle sur ces meilleurs params car il peut encore faire mieux

from sklearn.pipeline import Pipeline
from sklearn.model_selection import GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn import decomposition



# on contruit un pipline avec le modele, ainsi qu'un SCALER et un decompositeur de type PCA
std_slc = StandardScaler() #SCAL DATTA
pca = decomposition.PCA() # GET  most of the varience
pipe = Pipeline(steps=[('std_slc', std_slc),
                       ('pca', pca),
                       ('dec_tree', classifier)])


# hyper params to toon : on choisi dans un dico les HP du modéle suceptible d'etre regler et on leur donne chacun un range de valeurs differentes
n_components = list(range(1,X.shape[1]+1,1))
criterion = ['gini', 'entropy']
max_depth = [2,4,6,8,10,12]

#my dict of params
parameters = dict(pca__n_components=n_components,
                  dec_tree__criterion=criterion,
                  dec_tree__max_depth=max_depth)

#GRID SEARCH CV : cet outils va entrainer le modele avec a chaque iteration une combinaison de params donnée
clf_GS = GridSearchCV(pipe, parameters)
print('START TOONING')
clf_GS.fit(X, y)

# on afiche les resultat du reglage
print('Best Criterion:', clf_GS.best_estimator_.get_params()['dec_tree__criterion'])
print('Best max_depth:', clf_GS.best_estimator_.get_params()['dec_tree__max_depth'])
print('Best Number Of Components:', clf_GS.best_estimator_.get_params()['pca__n_components'])
print(); print(clf_GS.best_estimator_.get_params()['dec_tree'])


# on reentraine avec cette fois ci la meilleur version du modele
clf_GS.best_estimator_.fit(X_train, y_train)
y_pred = clf_GS.best_estimator_.predict(X_test)

print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))


# In[204]:


clf_GS.best_estimator_['dec_tree']


# In[203]:


fig = plt.figure(figsize=(15,15))
_ = tree.plot_tree(clf_GS.best_estimator_['dec_tree'],
                   feature_names=X.columns,
                   class_names=y.unique(),
                   filled=True)


# # regression

# In[205]:


from sklearn.tree import DecisionTreeRegressor
np.random.seed(1)
y = myTable['PFS1']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)
regressor = DecisionTreeRegressor()
regressor.fit(X_train, y_train)

y_pred = regressor.predict(X_test)
df=pd.DataFrame({'Actual':y_test, 'Predicted':y_pred})
df.head()


# In[209]:


barWidth = 0.25
fig = plt.subplots(figsize =(12, 8))

IT = df['Actual'].tolist()
ECE = df['Predicted'].tolist()

br1 = np.arange(len(IT))
br2 = [x + barWidth for x in br1]

plt.bar(br1, IT, color ='g', width = barWidth,
        edgecolor ='grey', label ='Actual PFS1')
plt.bar(br2, ECE, color ='r', width = barWidth,
        edgecolor ='grey', label ='Predicted PFS1')

plt.xticks([r + barWidth for r in range(len(IT))],
        df.index.tolist())

plt.xticks(rotation = 90)
plt.grid('True')
plt.legend()
plt.show()


# In[210]:


from sklearn import metrics
print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))
print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))


# In[211]:


fig = plt.figure(figsize=(25,20))
_ = tree.plot_tree(regressor,
                   feature_names=X.columns,
                   class_names=y.unique(),
                   filled=True)


# In[ ]:
